{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNDonla6UtLL"
   },
   "source": [
    "### Resources\n",
    "\n",
    "- https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf\n",
    "- https://arxiv.org/pdf/1312.5602\n",
    "- https://www.lesswrong.com/posts/kyvCNgx9oAwJCuevo/deep-q-networks-explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8p6bFDwGUtLQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import gymnasium as gym\n",
    "import ale_py\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import deque\n",
    "from gymnasium.wrappers import FrameStack\n",
    "from stable_baselines3.common.atari_wrappers import (\n",
    "    AtariWrapper,\n",
    "    FireResetEnv,\n",
    "    EpisodicLifeEnv,\n",
    "    MaxAndSkipEnv,\n",
    ")\n",
    "\n",
    "gym.register_envs(ale_py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVsLT3IJUtLR"
   },
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SN1JaFMNUtLR"
   },
   "outputs": [],
   "source": [
    "def display_frame(frame, gray=False):\n",
    "    if gray:\n",
    "        plt.imshow(frame, cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(frame)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kwBF80aEUtLS"
   },
   "outputs": [],
   "source": [
    "def display_multiple_frames(frames):\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(15, 5))\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.imshow(frames[i], cmap='gray')\n",
    "        ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "t2iioEZWUtLS"
   },
   "outputs": [],
   "source": [
    "def make_env(game, render='rgb_array'):\n",
    "    env = gym.make(game, render_mode=render)\n",
    "    env = AtariWrapper(env)\n",
    "    env = FrameStack(env, num_stack=4)\n",
    "    env = MaxAndSkipEnv(env, skip=4)\n",
    "    env = EpisodicLifeEnv(env)\n",
    "    env = FireResetEnv(env)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fxvMTp0-UtLS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.10.1+6a7e0ae)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "env = make_env('PongNoFrameskip-v4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N389sX_xUtLS"
   },
   "source": [
    "Before processing state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "c4u6dPIuUtLS",
    "outputId": "b1602271-16f6-4ca3-b7ca-1e7b25658ec7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs, info = env.reset()\n",
    "display_frame(obs[-1], gray=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "id": "l-nCcRrYUtLT",
    "outputId": "585dcbe9-72e0-41af-853f-57f6ada65fbc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs, info = env.reset()\n",
    "display_multiple_frames(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWyj-fAFUtLT"
   },
   "source": [
    "### Experience Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "ti6IvoK8UtLT"
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "\n",
    "    def __init__(self, capacity=10000) -> None:\n",
    "        self._buffer_obs = deque(maxlen=capacity)\n",
    "        self._buffer_acts = deque(maxlen=capacity)\n",
    "        self._buffer_rs = deque(maxlen=capacity)\n",
    "        self._buffer_obs_ps = deque(maxlen=capacity)\n",
    "        self._buffer_dones = deque(maxlen=capacity)\n",
    "\n",
    "        self._buffers = [self._buffer_obs, self._buffer_acts, self._buffer_rs, self._buffer_obs_ps, self._buffer_dones]\n",
    "\n",
    "    def store(self, experience: tuple) -> None:\n",
    "        for i, thing in enumerate(experience):\n",
    "            self._buffers[i].append(thing)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        indices = np.random.randint(0, high=len(self), size=(batch_size))\n",
    "\n",
    "        observations, actions, rewards, obs_primes, dones = self.buffers\n",
    "        return (\n",
    "            np.take(observations, indices, axis=0),\n",
    "            np.take(actions, indices, axis=0).reshape(-1, 1),\n",
    "            np.take(rewards, indices, axis=0).reshape(-1, 1),\n",
    "            np.take(obs_primes, indices, axis=0),\n",
    "            np.take(dones, indices, axis=0).reshape(-1, 1),\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._buffer_obs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return tuple([buffer[index] for buffer in self._buffers])\n",
    "\n",
    "    def __setitem__(self, index, value: tuple):\n",
    "        for i, buffer in enumerate(self._buffers):\n",
    "            buffer[index] = value[i]\n",
    "\n",
    "    def shuffle(self):\n",
    "        np.random.shuffle(self.buffer)\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        if len(self._buffer_obs) > 0:\n",
    "            shape = (len(self._buffer_obs), 5)\n",
    "            return shape\n",
    "        else:\n",
    "            return (0,)\n",
    "\n",
    "    @property\n",
    "    def buffers(self):\n",
    "      npbuffers = [np.array(buffer) for buffer in self._buffers]\n",
    "      return tuple(npbuffers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t1xMD1agUtLT",
    "outputId": "2a0837fb-e5e7-4aa3-86b5-81c317d2add6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "NUM_EPS = 100\n",
    "buffer_pong = ReplayBuffer()\n",
    "\n",
    "for episode in range(NUM_EPS):\n",
    "    done = False\n",
    "    observation, _ = env.reset()\n",
    "    step = 1\n",
    "\n",
    "    next_state = [observation]\n",
    "\n",
    "    while not done:\n",
    "        action = env.action_space.sample()\n",
    "\n",
    "        observation_prime, reward, terminated, truncated, _ = env.step(action)\n",
    "        buffer_pong.store((observation[:, :, :, 0], action, reward, observation_prime[:, :, :, 0], terminated or truncated))\n",
    "        observation = observation_prime\n",
    "\n",
    "        done = terminated or truncated\n",
    "\n",
    "print(len(buffer_pong))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "4naELqhxUtLT",
    "outputId": "e2868b0d-b3c4-4f41-9765-0cb36c657a96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 84, 84)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frame = buffer_pong[10][3]\n",
    "print(frame.shape)\n",
    "display_multiple_frames(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fUBSRCIIUtLU"
   },
   "outputs": [],
   "source": [
    "with open('replays/replay1.pkl', 'wb') as f:\n",
    "    pickle.dump(buffer_pong, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1BarzFKfUtLU",
    "outputId": "4dc31d5a-c9dc-46b5-ed04-ca7b09a11c6b"
   },
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        env,\n",
    "        in_channels = 4,\n",
    "        num_actions = 6,\n",
    "        hidden_filters = [16, 32],\n",
    "        start_epsilon = 0.99,\n",
    "        max_decay = 0.1,\n",
    "        decay_steps = 1000,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.start_epsilon = start_epsilon\n",
    "        self.epsilon = start_epsilon\n",
    "        self.max_decay = max_decay\n",
    "        self.decay_steps = decay_steps\n",
    "        self.env = env\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden_filters[0], kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_filters[0], hidden_filters[1], kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.Linear(hidden_filters[1] * 9 * 9, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_actions)\n",
    "        )\n",
    "\n",
    "        self.apply(self._init)\n",
    "\n",
    "    def _init(self, m):\n",
    "      if isinstance(m, (nn.Linear, nn.Conv2d)):\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "          nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x / 255.0)\n",
    "\n",
    "    def epsilon_greedy(self, state, dim=1):\n",
    "        q_values = self(state)\n",
    "        rng = np.random.random()\n",
    "\n",
    "        if rng < self.epsilon:\n",
    "            action = self.env.action_space.sample()\n",
    "        else:\n",
    "            action = torch.argmax(q_values, dim=dim)\n",
    "\n",
    "        return np.int64(action)\n",
    "\n",
    "    def epsilon_decay(self, step):\n",
    "        self.epsilon = self.max_decay + (self.start_epsilon - self.max_decay) * max(0, (self.decay_steps - step) / self.decay_steps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3PhWZY8OUtLU"
   },
   "source": [
    "Training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Be-UnFyDUtLU",
    "outputId": "267a80ee-0dd3-4651-b8f2-e14885e43311"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Last loss: 0.08380358666181564\n",
      "Episode: 2, Last loss: 0.054279036819934845\n",
      "Episode: 3, Last loss: 0.06152406334877014\n",
      "Episode: 4, Last loss: 0.0072293211705982685\n",
      "Episode: 5, Last loss: 0.009798569604754448\n",
      "Episode: 6, Last loss: 0.006577817723155022\n",
      "Episode: 7, Last loss: 0.07612144947052002\n",
      "Episode: 8, Last loss: 0.010602391324937344\n",
      "Episode: 9, Last loss: 0.025510592386126518\n",
      "Episode: 10, Last loss: 0.011926836334168911\n",
      "Episode: 11, Last loss: 0.0074654389172792435\n",
      "Episode: 12, Last loss: 0.008179208263754845\n",
      "Episode: 13, Last loss: 0.015239791944622993\n",
      "Episode: 14, Last loss: 0.025628594681620598\n",
      "Episode: 15, Last loss: 0.023219378665089607\n",
      "Episode: 16, Last loss: 0.002635975368320942\n",
      "Episode: 17, Last loss: 0.02234048955142498\n",
      "Episode: 18, Last loss: 0.0026851759757846594\n",
      "Episode: 19, Last loss: 0.017188379541039467\n",
      "Episode: 20, Last loss: 0.007014555390924215\n"
     ]
    }
   ],
   "source": [
    "EPISODES = 20\n",
    "LR = 2.5e-4\n",
    "BATCH_SIZE = 32\n",
    "C = 10000\n",
    "GAMMA = 0.99\n",
    "FINAL_ANNEAL = 1000000\n",
    "\n",
    "q_network = DQN(env, decay_steps=FINAL_ANNEAL)\n",
    "target_network = DQN(env, decay_steps=FINAL_ANNEAL)\n",
    "target_network.load_state_dict(q_network.state_dict())\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(q_network.parameters(), lr=LR)\n",
    "\n",
    "step = 0\n",
    "episode = 0\n",
    "for episode in range(EPISODES):\n",
    "\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    episode += 1\n",
    "\n",
    "    while not done:\n",
    "        batched_obs = obs[np.newaxis, :, :, :, 0]\n",
    "        action = q_network.epsilon_greedy(torch.tensor(batched_obs).float()).item()\n",
    "        obs_prime, reward, terminated, trunctated, _ = env.step(action)\n",
    "\n",
    "        buffer_pong.store((obs[:, :, :, 0], action, reward, obs_prime[:, :, :, 0], terminated or truncated))\n",
    "\n",
    "        observations, actions, rewards, observation_primes, dones = buffer_pong.sample(BATCH_SIZE)\n",
    "        with torch.no_grad():\n",
    "            q_values_minus = target_network(torch.tensor(observation_primes).float())\n",
    "            boostrapped_values = torch.amax(q_values_minus, dim=1, keepdim=True)\n",
    "\n",
    "        terminated_primes = torch.tensor(dones).bool()\n",
    "        actions = torch.tensor(actions, dtype=torch.int64)\n",
    "        rewards = torch.tensor(rewards).float()\n",
    "        y_trues = torch.empty((BATCH_SIZE, 1))\n",
    "\n",
    "        y_trues = torch.where(terminated_primes, rewards, rewards + GAMMA * boostrapped_values)\n",
    "        y_preds = q_network(torch.tensor(observations).float())\n",
    "\n",
    "        loss = loss_func(y_preds.gather(1, actions), y_trues)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        step += 1\n",
    "        q_network.epsilon_decay(step)\n",
    "        target_network.epsilon_decay(step)\n",
    "\n",
    "        done = terminated or truncated\n",
    "        obs = obs_prime\n",
    "        if step % C == 0:\n",
    "            target_network.load_state_dict(q_network.state_dict())\n",
    "    print(f'Episode: {episode}, Last loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "Mmix3Z4XKDJn"
   },
   "outputs": [],
   "source": [
    "torch.save(q_network.state_dict(), 'q_net1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQN(\n",
       "  (layers): Sequential(\n",
       "    (0): Conv2d(4, 16, kernel_size=(8, 8), stride=(4, 4))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (3): ReLU()\n",
       "    (4): Flatten(start_dim=1, end_dim=-1)\n",
       "    (5): Linear(in_features=2592, out_features=512, bias=True)\n",
       "    (6): ReLU()\n",
       "    (7): Linear(in_features=512, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env2 = make_env('PongNoFrameskip-v4', render='human')\n",
    "\n",
    "q_network_trained = DQN(env)\n",
    "q_network_trained.load_state_dict(torch.load('q_net1.pt', weights_only=True))\n",
    "q_network_trained.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = False\n",
    "total_reward = 0\n",
    "\n",
    "obs, _ = env2.reset()\n",
    "while not done:\n",
    "    batched_obs = obs[np.newaxis, :, :, :, 0]\n",
    "    with torch.no_grad():\n",
    "        logits = q_network_trained(torch.tensor(batched_obs).float())\n",
    "        action = torch.argmax(logits, dim=1).item()\n",
    "        \n",
    "    next_observation, reward, terminated, truncated, _ = env2.step(action)\n",
    "    total_reward += reward\n",
    "    obs = next_observation\n",
    "    \n",
    "    done = terminated or truncated\n",
    "    \n",
    "env2.close()\n",
    "print(f'Total reward achieved: {total_reward}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
