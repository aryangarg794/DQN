{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNDonla6UtLL"
   },
   "source": [
    "### Resources\n",
    "\n",
    "- https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf\n",
    "- https://arxiv.org/pdf/1312.5602\n",
    "- https://www.lesswrong.com/posts/kyvCNgx9oAwJCuevo/deep-q-networks-explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SCuXR45cU2m7",
    "outputId": "29fc5273-2c1a-4032-b31a-a4f47ca8c142"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stable_baselines3\n",
      "  Downloading stable_baselines3-2.3.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting gymnasium<0.30,>=0.28.1 (from stable_baselines3)\n",
      "  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.5.0+cu121)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (3.1.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.2.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (4.12.2)\n",
      "Collecting farama-notifications>=0.0.1 (from gymnasium<0.30,>=0.28.1->stable_baselines3)\n",
      "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.16.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13->stable_baselines3) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable_baselines3) (3.0.2)\n",
      "Downloading stable_baselines3-2.3.2-py3-none-any.whl (182 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Installing collected packages: farama-notifications, gymnasium, stable_baselines3\n",
      "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1 stable_baselines3-2.3.2\n",
      "Collecting ale_py\n",
      "  Downloading ale_py-0.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: numpy>1.20 in /usr/local/lib/python3.10/dist-packages (from ale_py) (1.26.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from ale_py) (4.12.2)\n",
      "Downloading ale_py-0.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ale_py\n",
      "Successfully installed ale_py-0.10.1\n"
     ]
    }
   ],
   "source": [
    "# colab requirements\n",
    "!pip install stable_baselines3\n",
    "!pip install ale_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T23:39:27.913282Z",
     "iopub.status.busy": "2024-11-11T23:39:27.912965Z",
     "iopub.status.idle": "2024-11-11T23:39:33.597815Z",
     "shell.execute_reply": "2024-11-11T23:39:33.597222Z",
     "shell.execute_reply.started": "2024-11-11T23:39:27.913260Z"
    },
    "id": "8p6bFDwGUtLQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import gymnasium as gym\n",
    "import ale_py\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import deque\n",
    "from gymnasium.wrappers import FrameStack\n",
    "from stable_baselines3.common.atari_wrappers import (\n",
    "    AtariWrapper,\n",
    "    FireResetEnv,\n",
    "    EpisodicLifeEnv,\n",
    "    MaxAndSkipEnv,\n",
    ")\n",
    "\n",
    "gym.register_envs(ale_py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVsLT3IJUtLR"
   },
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T23:39:33.599404Z",
     "iopub.status.busy": "2024-11-11T23:39:33.598856Z",
     "iopub.status.idle": "2024-11-11T23:39:33.603184Z",
     "shell.execute_reply": "2024-11-11T23:39:33.602543Z",
     "shell.execute_reply.started": "2024-11-11T23:39:33.599370Z"
    },
    "id": "SN1JaFMNUtLR"
   },
   "outputs": [],
   "source": [
    "def display_frame(frame, gray=False):\n",
    "    if gray:\n",
    "        plt.imshow(frame, cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(frame)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T23:39:34.923366Z",
     "iopub.status.busy": "2024-11-11T23:39:34.923022Z",
     "iopub.status.idle": "2024-11-11T23:39:34.927294Z",
     "shell.execute_reply": "2024-11-11T23:39:34.926641Z",
     "shell.execute_reply.started": "2024-11-11T23:39:34.923344Z"
    },
    "id": "kwBF80aEUtLS"
   },
   "outputs": [],
   "source": [
    "def display_multiple_frames(frames):\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(15, 5))\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.imshow(frames[i], cmap='gray')\n",
    "        ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T23:51:03.780304Z",
     "iopub.status.busy": "2024-11-11T23:51:03.779976Z",
     "iopub.status.idle": "2024-11-11T23:51:03.784161Z",
     "shell.execute_reply": "2024-11-11T23:51:03.783388Z",
     "shell.execute_reply.started": "2024-11-11T23:51:03.780284Z"
    },
    "id": "t2iioEZWUtLS"
   },
   "outputs": [],
   "source": [
    "def make_env(game):\n",
    "    env = gym.make(game, render_mode='rgb_array', )\n",
    "    env = AtariWrapper(env, terminal_on_life_loss=False)\n",
    "    env = FrameStack(env, num_stack=4)\n",
    "    env = MaxAndSkipEnv(env, skip=4)\n",
    "    env = EpisodicLifeEnv(env)\n",
    "    env = FireResetEnv(env)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T23:51:05.016343Z",
     "iopub.status.busy": "2024-11-11T23:51:05.016019Z",
     "iopub.status.idle": "2024-11-11T23:51:05.180595Z",
     "shell.execute_reply": "2024-11-11T23:51:05.180055Z",
     "shell.execute_reply.started": "2024-11-11T23:51:05.016322Z"
    },
    "id": "fxvMTp0-UtLS"
   },
   "outputs": [],
   "source": [
    "env = make_env('PongNoFrameskip-v4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N389sX_xUtLS"
   },
   "source": [
    "Before processing state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "execution": {
     "iopub.execute_input": "2024-11-11T23:51:07.812262Z",
     "iopub.status.busy": "2024-11-11T23:51:07.811955Z",
     "iopub.status.idle": "2024-11-11T23:51:07.871433Z",
     "shell.execute_reply": "2024-11-11T23:51:07.870880Z",
     "shell.execute_reply.started": "2024-11-11T23:51:07.812241Z"
    },
    "id": "c4u6dPIuUtLS",
    "outputId": "20d622dd-9c39-4f03-b51d-fa26fa3eaa3b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs, info = env.reset()\n",
    "display_frame(obs[-1], gray=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "execution": {
     "iopub.execute_input": "2024-11-11T23:51:09.862117Z",
     "iopub.status.busy": "2024-11-11T23:51:09.861803Z",
     "iopub.status.idle": "2024-11-11T23:51:09.959997Z",
     "shell.execute_reply": "2024-11-11T23:51:09.959330Z",
     "shell.execute_reply.started": "2024-11-11T23:51:09.862096Z"
    },
    "id": "l-nCcRrYUtLT",
    "outputId": "8bc1cbc5-343d-4f48-ce73-a1875dc26f4b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs, info = env.reset()\n",
    "display_multiple_frames(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWyj-fAFUtLT"
   },
   "source": [
    "### Experience Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T23:51:11.931867Z",
     "iopub.status.busy": "2024-11-11T23:51:11.931525Z",
     "iopub.status.idle": "2024-11-11T23:51:11.940279Z",
     "shell.execute_reply": "2024-11-11T23:51:11.939504Z",
     "shell.execute_reply.started": "2024-11-11T23:51:11.931845Z"
    },
    "id": "ti6IvoK8UtLT"
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "\n",
    "    def __init__(self, capacity=50000) -> None:\n",
    "        self._buffer_obs = deque(maxlen=capacity)\n",
    "        self._buffer_acts = deque(maxlen=capacity)\n",
    "        self._buffer_rs = deque(maxlen=capacity)\n",
    "        self._buffer_obs_ps = deque(maxlen=capacity)\n",
    "        self._buffer_dones = deque(maxlen=capacity)\n",
    "\n",
    "        self._buffers = [self._buffer_obs, self._buffer_acts, self._buffer_rs, self._buffer_obs_ps, self._buffer_dones]\n",
    "\n",
    "    def store(self, experience: tuple) -> None:\n",
    "        for i, thing in enumerate(experience):\n",
    "            self._buffers[i].append(thing)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        indices = np.random.randint(0, high=len(self), size=(batch_size))\n",
    "\n",
    "        observations, actions, rewards, obs_primes, dones = self.buffers\n",
    "        return (\n",
    "            np.take(observations, indices, axis=0),\n",
    "            np.take(actions, indices, axis=0).reshape(-1, 1),\n",
    "            np.take(rewards, indices, axis=0).reshape(-1, 1),\n",
    "            np.take(obs_primes, indices, axis=0),\n",
    "            np.take(dones, indices, axis=0).reshape(-1, 1),\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._buffer_obs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return tuple([buffer[index] for buffer in self._buffers])\n",
    "\n",
    "    def __setitem__(self, index, value: tuple):\n",
    "        for i, buffer in enumerate(self._buffers):\n",
    "            buffer[index] = value[i]\n",
    "\n",
    "    def shuffle(self):\n",
    "        np.random.shuffle(self.buffer)\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        if len(self._buffer_obs) > 0:\n",
    "            shape = (len(self._buffer_obs), 5)\n",
    "            return shape\n",
    "        else:\n",
    "            return (0,)\n",
    "\n",
    "    @property\n",
    "    def buffers(self):\n",
    "      npbuffers = [np.array(buffer) for buffer in self._buffers]\n",
    "      return tuple(npbuffers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-11T23:51:13.724500Z",
     "iopub.status.busy": "2024-11-11T23:51:13.724178Z",
     "iopub.status.idle": "2024-11-11T23:55:00.276479Z",
     "shell.execute_reply": "2024-11-11T23:55:00.275794Z",
     "shell.execute_reply.started": "2024-11-11T23:51:13.724481Z"
    },
    "id": "t1xMD1agUtLT",
    "outputId": "030b8261-979b-49ce-855e-a3161edc8925"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "NUM_EPS = 250\n",
    "buffer_pong = ReplayBuffer()\n",
    "\n",
    "for episode in range(NUM_EPS):\n",
    "    done = False\n",
    "    observation, _ = env.reset()\n",
    "    step = 1\n",
    "\n",
    "    next_state = [observation]\n",
    "\n",
    "    while not done:\n",
    "        action = env.action_space.sample()\n",
    "\n",
    "        observation_prime, reward, terminated, truncated, _ = env.step(action)\n",
    "        buffer_pong.store((observation[:, :, :, 0], action, reward, observation_prime[:, :, :, 0], terminated or truncated))\n",
    "        observation = observation_prime\n",
    "\n",
    "        done = terminated or truncated\n",
    "\n",
    "print(len(buffer_pong))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "execution": {
     "iopub.execute_input": "2024-11-11T23:55:00.277795Z",
     "iopub.status.busy": "2024-11-11T23:55:00.277460Z",
     "iopub.status.idle": "2024-11-11T23:55:00.370240Z",
     "shell.execute_reply": "2024-11-11T23:55:00.369659Z",
     "shell.execute_reply.started": "2024-11-11T23:55:00.277776Z"
    },
    "id": "4naELqhxUtLT",
    "outputId": "8ae8045c-0fd7-4da5-8ec8-393fd79866bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 84, 84)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frame = buffer_pong[10][3]\n",
    "print(frame.shape)\n",
    "display_multiple_frames(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fUBSRCIIUtLU"
   },
   "outputs": [],
   "source": [
    "with open('replays/replay1.pkl', 'wb') as f:\n",
    "    pickle.dump(buffer_pong, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T00:28:15.751279Z",
     "iopub.status.busy": "2024-11-12T00:28:15.750977Z",
     "iopub.status.idle": "2024-11-12T00:28:15.759495Z",
     "shell.execute_reply": "2024-11-12T00:28:15.758873Z",
     "shell.execute_reply.started": "2024-11-12T00:28:15.751258Z"
    },
    "id": "1BarzFKfUtLU"
   },
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        env,\n",
    "        in_channels = 4,\n",
    "        num_actions = 6,\n",
    "        hidden_filters = [16, 32],\n",
    "        start_epsilon = 0.99,\n",
    "        max_decay = 0.1,\n",
    "        decay_steps = 1000,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.start_epsilon = start_epsilon\n",
    "        self.epsilon = start_epsilon\n",
    "        self.max_decay = max_decay\n",
    "        self.decay_steps = decay_steps\n",
    "        self.env = env\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden_filters[0], kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_filters[0], hidden_filters[1], kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.Linear(hidden_filters[1] * 9 * 9, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_actions)\n",
    "        )\n",
    "\n",
    "        self.apply(self._init)\n",
    "\n",
    "    def _init(self, m):\n",
    "      if isinstance(m, (nn.Linear, nn.Conv2d)):\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "          nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x / 255.0)\n",
    "\n",
    "    def epsilon_greedy(self, state, dim=1):\n",
    "        with torch.no_grad():\n",
    "            q_values = self(state)\n",
    "        rng = np.random.random()\n",
    "\n",
    "        if rng < self.epsilon:\n",
    "            action = self.env.action_space.sample()\n",
    "            action = torch.tensor(action)\n",
    "        else:\n",
    "            action = torch.argmax(q_values, dim=dim)\n",
    "\n",
    "        return action\n",
    "\n",
    "    def epsilon_decay(self, step):\n",
    "        self.epsilon = self.max_decay + (self.start_epsilon - self.max_decay) * max(0, (self.decay_steps - step) / self.decay_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "execution": {
     "iopub.execute_input": "2024-11-12T00:28:18.005912Z",
     "iopub.status.busy": "2024-11-12T00:28:18.005608Z",
     "iopub.status.idle": "2024-11-12T00:28:18.010252Z",
     "shell.execute_reply": "2024-11-12T00:28:18.009720Z",
     "shell.execute_reply.started": "2024-11-12T00:28:18.005892Z"
    },
    "id": "36BFYfnBS8lK",
    "outputId": "7602ea77-0c1f-49f9-d574-b2865f9e58a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3PhWZY8OUtLU"
   },
   "source": [
    "Training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "execution": {
     "iopub.execute_input": "2024-11-12T00:46:24.744075Z",
     "iopub.status.busy": "2024-11-12T00:46:24.743759Z",
     "iopub.status.idle": "2024-11-12T11:28:17.924456Z",
     "shell.execute_reply": "2024-11-12T11:28:17.923216Z",
     "shell.execute_reply.started": "2024-11-12T00:46:24.744054Z"
    },
    "id": "Be-UnFyDUtLU",
    "outputId": "865ed6ba-898d-45ab-a49e-347e7139d8cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 6391, Loss: 0.0170, Epsilon: 0.9843, Reward: -11.0\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 41565, Loss: 0.0029, Epsilon: 0.9530, Reward: -25.0\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m     rewards_list\u001b[38;5;241m.\u001b[39mappend(total_reward)\n\u001b[1;32m     30\u001b[0m     total_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 32\u001b[0m observations, actions, rewards, observation_primes, dones \u001b[38;5;241m=\u001b[39m \u001b[43mbuffer_pong\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     34\u001b[0m     q_values_minus \u001b[38;5;241m=\u001b[39m target_network(torch\u001b[38;5;241m.\u001b[39mtensor(observation_primes)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device))\n",
      "Cell \u001b[0;32mIn[19], line 19\u001b[0m, in \u001b[0;36mReplayBuffer.sample\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch_size):\n\u001b[1;32m     17\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, high\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m), size\u001b[38;5;241m=\u001b[39m(batch_size))\n\u001b[0;32m---> 19\u001b[0m     observations, actions, rewards, obs_primes, dones \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffers\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m     21\u001b[0m         np\u001b[38;5;241m.\u001b[39mtake(observations, indices, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m     22\u001b[0m         np\u001b[38;5;241m.\u001b[39mtake(actions, indices, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m         np\u001b[38;5;241m.\u001b[39mtake(dones, indices, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     26\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[19], line 51\u001b[0m, in \u001b[0;36mReplayBuffer.buffers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuffers\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 51\u001b[0m   npbuffers \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffers\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     52\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(npbuffers)\n",
      "Cell \u001b[0;32mIn[19], line 51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuffers\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 51\u001b[0m   npbuffers \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39marray(buffer) \u001b[38;5;28;01mfor\u001b[39;00m buffer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffers]\n\u001b[1;32m     52\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(npbuffers)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TIMESTEPS = 50000\n",
    "LR = 1e-4\n",
    "BATCH_SIZE = 32\n",
    "C = 500\n",
    "GAMMA = 0.99\n",
    "STATS = 5000\n",
    "\n",
    "q_network = DQN(env, decay_steps=TIMESTEPS).to(device)\n",
    "target_network = DQN(env, decay_steps=TIMESTEPS).to(device)\n",
    "target_network.load_state_dict(q_network.state_dict())\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(q_network.parameters(), lr=LR)\n",
    "\n",
    "total_reward = 0\n",
    "losses = []\n",
    "rewards_list = []\n",
    "\n",
    "for step in range(1, TIMESTEPS):\n",
    "\n",
    "    obs, _ = env.reset()\n",
    "    batched_obs = obs[np.newaxis, :, :, :, 0]\n",
    "    action = q_network.epsilon_greedy(torch.tensor(batched_obs).float().to(device)).cpu().item()\n",
    "    obs_prime, reward, terminated, trunctated, _ = env.step(action)\n",
    "\n",
    "    buffer_pong.store((obs[:, :, :, 0], action, reward, obs_prime[:, :, :, 0], terminated or truncated))\n",
    "    total_reward += reward\n",
    "    if terminated:\n",
    "        rewards_list.append(total_reward)\n",
    "        total_reward = 0\n",
    "\n",
    "    observations, actions, rewards, observation_primes, dones = buffer_pong.sample(BATCH_SIZE)\n",
    "    with torch.no_grad():\n",
    "        q_values_minus = target_network(torch.tensor(observation_primes).float().to(device))\n",
    "        boostrapped_values = torch.amax(q_values_minus, dim=1, keepdim=True)\n",
    "\n",
    "    terminated_primes = torch.tensor(dones).bool().to(device)\n",
    "    actions = torch.tensor(actions, dtype=torch.int64).to(device)\n",
    "    rewards = torch.tensor(rewards).float().to(device)\n",
    "    y_trues = torch.empty((BATCH_SIZE, 1)).to(device)\n",
    "\n",
    "    y_trues = torch.where(terminated_primes, rewards, rewards + GAMMA * boostrapped_values)\n",
    "    y_preds = q_network(torch.tensor(observations).float().to(device))\n",
    "\n",
    "    loss = loss_func(y_preds.gather(1, actions), y_trues)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    q_network.epsilon_decay(step)\n",
    "    target_network.epsilon_decay(step)\n",
    "    \n",
    "    obs = obs_prime\n",
    "    if step % C == 0:\n",
    "        target_network.load_state_dict(q_network.state_dict())\n",
    "\n",
    "    losses.append(loss)\n",
    "    print(f'Step: {step}, Loss: {loss:.4f}, Epsilon: {q_network.epsilon:.4f}, Reward: {rewards_list[-1] if len(rewards_list) > 0 else 0.0}',\n",
    "          end='\\r',\n",
    "          flush=True\n",
    "    )\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-12T11:28:17.924918Z",
     "iopub.status.idle": "2024-11-12T11:28:17.925141Z",
     "shell.execute_reply": "2024-11-12T11:28:17.925043Z",
     "shell.execute_reply.started": "2024-11-12T11:28:17.925032Z"
    },
    "id": "Mmix3Z4XKDJn"
   },
   "outputs": [],
   "source": [
    "torch.save(q_network.state_dict(), 'q_net1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uGjmYY5-ScgB"
   },
   "outputs": [],
   "source": [
    "env_test = make_env('PongNoFrameskip-v4', render='human')\n",
    "\n",
    "q_network_trained = DQN(env_test)\n",
    "q_network_trained.load_state_dict(torch.load('q_net1.pt', weights_only=True))\n",
    "q_network_trained.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zRfzxJMaSd4W"
   },
   "outputs": [],
   "source": [
    "done = False\n",
    "total_reward = 0\n",
    "\n",
    "obs, _ = env_test.reset()\n",
    "while not done:\n",
    "    batched_obs = obs[np.newaxis, :, :, :, 0]\n",
    "    with torch.no_grad():\n",
    "        logits = q_network_trained(torch.tensor(batched_obs).float())\n",
    "        action = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "    next_observation, reward, terminated, truncated, _ = env_test.step(action)\n",
    "    total_reward += reward\n",
    "    obs = next_observation\n",
    "\n",
    "    done = terminated or truncated\n",
    "\n",
    "env_test.close()\n",
    "print(f'Total reward achieved: {total_reward}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
