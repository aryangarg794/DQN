{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNDonla6UtLL"
   },
   "source": [
    "### Resources\n",
    "\n",
    "- https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf\n",
    "- https://arxiv.org/pdf/1312.5602\n",
    "- https://www.lesswrong.com/posts/kyvCNgx9oAwJCuevo/deep-q-networks-explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SCuXR45cU2m7",
    "outputId": "29fc5273-2c1a-4032-b31a-a4f47ca8c142"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stable_baselines3\n",
      "  Downloading stable_baselines3-2.3.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting gymnasium<0.30,>=0.28.1 (from stable_baselines3)\n",
      "  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.5.0+cu121)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (3.1.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.2.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (4.12.2)\n",
      "Collecting farama-notifications>=0.0.1 (from gymnasium<0.30,>=0.28.1->stable_baselines3)\n",
      "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.16.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13->stable_baselines3) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable_baselines3) (3.0.2)\n",
      "Downloading stable_baselines3-2.3.2-py3-none-any.whl (182 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Installing collected packages: farama-notifications, gymnasium, stable_baselines3\n",
      "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1 stable_baselines3-2.3.2\n",
      "Collecting ale_py\n",
      "  Downloading ale_py-0.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: numpy>1.20 in /usr/local/lib/python3.10/dist-packages (from ale_py) (1.26.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from ale_py) (4.12.2)\n",
      "Downloading ale_py-0.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ale_py\n",
      "Successfully installed ale_py-0.10.1\n"
     ]
    }
   ],
   "source": [
    "# colab requirements\n",
    "!pip install stable_baselines3\n",
    "!pip install ale_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8p6bFDwGUtLQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import gymnasium as gym\n",
    "import ale_py\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import deque\n",
    "from gymnasium.wrappers import FrameStack\n",
    "from stable_baselines3.common.atari_wrappers import (\n",
    "    AtariWrapper,\n",
    "    FireResetEnv,\n",
    "    EpisodicLifeEnv,\n",
    "    MaxAndSkipEnv,\n",
    ")\n",
    "\n",
    "gym.register_envs(ale_py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVsLT3IJUtLR"
   },
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SN1JaFMNUtLR"
   },
   "outputs": [],
   "source": [
    "def display_frame(frame, gray=False):\n",
    "    if gray:\n",
    "        plt.imshow(frame, cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(frame)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kwBF80aEUtLS"
   },
   "outputs": [],
   "source": [
    "def display_multiple_frames(frames):\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(15, 5))\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.imshow(frames[i], cmap='gray')\n",
    "        ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "t2iioEZWUtLS"
   },
   "outputs": [],
   "source": [
    "def make_env(game):\n",
    "    env = gym.make(game, render_mode='rgb_array')\n",
    "    env = AtariWrapper(env)\n",
    "    env = FrameStack(env, num_stack=4)\n",
    "    env = MaxAndSkipEnv(env, skip=4)\n",
    "    env = EpisodicLifeEnv(env)\n",
    "    env = FireResetEnv(env)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fxvMTp0-UtLS"
   },
   "outputs": [],
   "source": [
    "env = make_env('PongNoFrameskip-v4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N389sX_xUtLS"
   },
   "source": [
    "Before processing state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "c4u6dPIuUtLS",
    "outputId": "20d622dd-9c39-4f03-b51d-fa26fa3eaa3b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs, info = env.reset()\n",
    "display_frame(obs[-1], gray=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "l-nCcRrYUtLT",
    "outputId": "8bc1cbc5-343d-4f48-ce73-a1875dc26f4b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs, info = env.reset()\n",
    "display_multiple_frames(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWyj-fAFUtLT"
   },
   "source": [
    "### Experience Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ti6IvoK8UtLT"
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "\n",
    "    def __init__(self, capacity=50000) -> None:\n",
    "        self._buffer_obs = deque(maxlen=capacity)\n",
    "        self._buffer_acts = deque(maxlen=capacity)\n",
    "        self._buffer_rs = deque(maxlen=capacity)\n",
    "        self._buffer_obs_ps = deque(maxlen=capacity)\n",
    "        self._buffer_dones = deque(maxlen=capacity)\n",
    "\n",
    "        self._buffers = [self._buffer_obs, self._buffer_acts, self._buffer_rs, self._buffer_obs_ps, self._buffer_dones]\n",
    "\n",
    "    def store(self, experience: tuple) -> None:\n",
    "        for i, thing in enumerate(experience):\n",
    "            self._buffers[i].append(thing)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        indices = np.random.randint(0, high=len(self), size=(batch_size))\n",
    "\n",
    "        observations, actions, rewards, obs_primes, dones = self.buffers\n",
    "        return (\n",
    "            np.take(observations, indices, axis=0),\n",
    "            np.take(actions, indices, axis=0).reshape(-1, 1),\n",
    "            np.take(rewards, indices, axis=0).reshape(-1, 1),\n",
    "            np.take(obs_primes, indices, axis=0),\n",
    "            np.take(dones, indices, axis=0).reshape(-1, 1),\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._buffer_obs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return tuple([buffer[index] for buffer in self._buffers])\n",
    "\n",
    "    def __setitem__(self, index, value: tuple):\n",
    "        for i, buffer in enumerate(self._buffers):\n",
    "            buffer[index] = value[i]\n",
    "\n",
    "    def shuffle(self):\n",
    "        np.random.shuffle(self.buffer)\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        if len(self._buffer_obs) > 0:\n",
    "            shape = (len(self._buffer_obs), 5)\n",
    "            return shape\n",
    "        else:\n",
    "            return (0,)\n",
    "\n",
    "    @property\n",
    "    def buffers(self):\n",
    "      npbuffers = [np.array(buffer) for buffer in self._buffers]\n",
    "      return tuple(npbuffers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t1xMD1agUtLT",
    "outputId": "030b8261-979b-49ce-855e-a3161edc8925"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43480\n"
     ]
    }
   ],
   "source": [
    "NUM_EPS = 200\n",
    "buffer_pong = ReplayBuffer()\n",
    "\n",
    "for episode in range(NUM_EPS):\n",
    "    done = False\n",
    "    observation, _ = env.reset()\n",
    "    step = 1\n",
    "\n",
    "    next_state = [observation]\n",
    "\n",
    "    while not done:\n",
    "        action = env.action_space.sample()\n",
    "\n",
    "        observation_prime, reward, terminated, truncated, _ = env.step(action)\n",
    "        buffer_pong.store((observation[:, :, :, 0], action, reward, observation_prime[:, :, :, 0], terminated or truncated))\n",
    "        observation = observation_prime\n",
    "\n",
    "        done = terminated or truncated\n",
    "\n",
    "print(len(buffer_pong))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "4naELqhxUtLT",
    "outputId": "8ae8045c-0fd7-4da5-8ec8-393fd79866bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 84, 84)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frame = buffer_pong[10][3]\n",
    "print(frame.shape)\n",
    "display_multiple_frames(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fUBSRCIIUtLU"
   },
   "outputs": [],
   "source": [
    "with open('replays/replay1.pkl', 'wb') as f:\n",
    "    pickle.dump(buffer_pong, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "1BarzFKfUtLU"
   },
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        env,\n",
    "        in_channels = 4,\n",
    "        num_actions = 6,\n",
    "        hidden_filters = [16, 32],\n",
    "        start_epsilon = 0.99,\n",
    "        max_decay = 0.1,\n",
    "        decay_steps = 1000,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.start_epsilon = start_epsilon\n",
    "        self.epsilon = start_epsilon\n",
    "        self.max_decay = max_decay\n",
    "        self.decay_steps = decay_steps\n",
    "        self.env = env\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden_filters[0], kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_filters[0], hidden_filters[1], kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.Linear(hidden_filters[1] * 9 * 9, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_actions)\n",
    "        )\n",
    "\n",
    "        self.apply(self._init)\n",
    "\n",
    "    def _init(self, m):\n",
    "      if isinstance(m, (nn.Linear, nn.Conv2d)):\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "          nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x / 255.0)\n",
    "\n",
    "    def epsilon_greedy(self, state, dim=1):\n",
    "        q_values = self(state)\n",
    "        rng = np.random.random()\n",
    "\n",
    "        if rng < self.epsilon:\n",
    "            action = self.env.action_space.sample()\n",
    "            action = torch.tensor(action)\n",
    "        else:\n",
    "            action = torch.argmax(q_values, dim=dim)\n",
    "\n",
    "        return action\n",
    "\n",
    "    def epsilon_decay(self, step):\n",
    "        self.epsilon = self.max_decay + (self.start_epsilon - self.max_decay) * max(0, (self.decay_steps - step) / self.decay_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "36BFYfnBS8lK",
    "outputId": "7602ea77-0c1f-49f9-d574-b2865f9e58a1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3PhWZY8OUtLU"
   },
   "source": [
    "Training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "id": "Be-UnFyDUtLU",
    "outputId": "865ed6ba-898d-45ab-a49e-347e7139d8cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-399e120bf4f6>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mtotal_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation_primes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffer_pong\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mq_values_minus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation_primes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-85eff2a8bb66>\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_primes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         return (\n\u001b[1;32m     21\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-85eff2a8bb66>\u001b[0m in \u001b[0;36mbuffers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m       \u001b[0mnpbuffers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpbuffers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-85eff2a8bb66>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m       \u001b[0mnpbuffers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpbuffers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TIMESTEPS = 1000000\n",
    "LR = 2.5e-4\n",
    "BATCH_SIZE = 32\n",
    "C = 1000\n",
    "GAMMA = 0.99\n",
    "STATS = 50000\n",
    "\n",
    "q_network = DQN(env, decay_steps=TIMESTEPS).to(device)\n",
    "target_network = DQN(env, decay_steps=TIMESTEPS).to(device)\n",
    "target_network.load_state_dict(q_network.state_dict())\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(q_network.parameters(), lr=LR)\n",
    "\n",
    "losses = []\n",
    "rewards_list = []\n",
    "\n",
    "for step in range(1, TIMESTEPS):\n",
    "\n",
    "    obs, _ = env.reset()\n",
    "    episode += 1\n",
    "    total_reward = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    batched_obs = obs[np.newaxis, :, :, :, 0]\n",
    "    action = q_network.epsilon_greedy(torch.tensor(batched_obs).float().to(device)).cpu().item()\n",
    "    obs_prime, reward, terminated, trunctated, _ = env.step(action)\n",
    "\n",
    "    buffer_pong.store((obs[:, :, :, 0], action, reward, obs_prime[:, :, :, 0], terminated or truncated))\n",
    "    total_reward += reward\n",
    "    if terminated or truncated:\n",
    "        rewards_list.append(total_reward)\n",
    "        total_reward = 0\n",
    "\n",
    "    observations, actions, rewards, observation_primes, dones = buffer_pong.sample(BATCH_SIZE)\n",
    "    with torch.no_grad():\n",
    "        q_values_minus = target_network(torch.tensor(observation_primes).float().to(device))\n",
    "        boostrapped_values = torch.amax(q_values_minus, dim=1, keepdim=True)\n",
    "\n",
    "    terminated_primes = torch.tensor(dones).bool().to(device)\n",
    "    actions = torch.tensor(actions, dtype=torch.int64).to(device)\n",
    "    rewards = torch.tensor(rewards).float().to(device)\n",
    "    y_trues = torch.empty((BATCH_SIZE, 1)).to(device)\n",
    "\n",
    "    y_trues = torch.where(terminated_primes, rewards, rewards + GAMMA * boostrapped_values)\n",
    "    y_preds = q_network(torch.tensor(observations).float().to(device))\n",
    "\n",
    "    loss = loss_func(y_preds.gather(1, actions), y_trues)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    q_network.epsilon_decay(step)\n",
    "    target_network.epsilon_decay(step)\n",
    "\n",
    "    done = terminated or truncated\n",
    "    obs = obs_prime\n",
    "    if step % C == 0:\n",
    "        target_network.load_state_dict(q_network.state_dict())\n",
    "\n",
    "    losses.append(loss)\n",
    "    print(f'Episode: {step}, Loss: {loss:.4f}, Epsilon: {q_network.epsilon:.4f}, Reward: {rewards_list[-1] if len(rewards_list) > 0 else 0.0}',\n",
    "          end='\\r',\n",
    "          flush=True\n",
    "    )\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "Mmix3Z4XKDJn"
   },
   "outputs": [],
   "source": [
    "torch.save(q_network.state_dict(), 'q_net1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uGjmYY5-ScgB"
   },
   "outputs": [],
   "source": [
    "env_test = make_env('PongNoFrameskip-v4', render='human')\n",
    "\n",
    "q_network_trained = DQN(env_test)\n",
    "q_network_trained.load_state_dict(torch.load('q_net1.pt', weights_only=True))\n",
    "q_network_trained.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zRfzxJMaSd4W"
   },
   "outputs": [],
   "source": [
    "done = False\n",
    "total_reward = 0\n",
    "\n",
    "obs, _ = env_test.reset()\n",
    "while not done:\n",
    "    batched_obs = obs[np.newaxis, :, :, :, 0]\n",
    "    with torch.no_grad():\n",
    "        logits = q_network_trained(torch.tensor(batched_obs).float())\n",
    "        action = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "    next_observation, reward, terminated, truncated, _ = env_test.step(action)\n",
    "    total_reward += reward\n",
    "    obs = next_observation\n",
    "\n",
    "    done = terminated or truncated\n",
    "\n",
    "env_test.close()\n",
    "print(f'Total reward achieved: {total_reward}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
